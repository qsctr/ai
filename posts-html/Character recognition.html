<h1 id="character-recognition">Character recognition</h1>
<p>See the source code on GitHub: <a href="https://github.com/qsctr/character-recognition">https://github.com/qsctr/character-recognition</a></p>
<p>Use the program: <a href="https://qsctr.github.io/character-recognition">https://qsctr.github.io/character-recognition</a> (If there is an error dialog, use a newer browser. Chrome is recommended.)</p>
<h2 id="4-6-2017">4/6/2017</h2>
<p>For this assignment we are supposed to train ten perceptrons corresponding to the digits 0 to 9, and then use them to classify a 5 by 7 pixel large input, for digit recognition. However, I decided to do character recognition instead, so it will work for letters as well, and with a higher resolution input. I will write it in HTML, CSS, and TypeScript, so it can run in a webpage.</p>
<p>Today I finished designing the UI for the program. It is divided into three main areas. The one on the left is the input box. The user can press a key on the keyboard to render that character into the box, or draw one themselves. The middle one is the output box. It shows what the computer thinks the input is. The one on the right has buttons that the user can press, such as for classification and training.</p>
<h2 id="4-10-2017">4/10/2017</h2>
<p>Today I finished the project. Currently the program recognizes lowercase and uppercase alphabetical letters, numeric digits, and space. However, this is just an arbitrary choice, since any character that is renderable by the computer can be used. For example, I tried training it with some Chinese characters, and it worked.</p>
<p>How it works is that one perceptron for each character to be recognized is created. If you want an explanation about perceptrons you can read the previous post about the perceptron project. However, this project is in TypeScript instead of Haskell, but the concept of perceptrons is still the same. But instead of getting x and y coordinates as inputs, the perceptrons in this project gets the pixels of the input picture as inputs. Since the current size of the canvas is 50 by 50 pixels, each perceptron has 2500 inputs, instead of 2.</p>
<p>Then, a training set is generated. Currently, 100 training samples are generated for each character, so since there are 63 characters in total, 6300 training samples are generated in total. The first one of each is just the normal rendering of that character into the 50 by 50 resolution canvas. But the 99 remaining ones have noise added in them, so some pixels might be darker or lighter randomly.</p>
<p>After that, the perceptrons are trained. Each perceptron is given the training samples of its corresponding digit with a target output of 1. The training samples of the other digits are given with a target of 0. The order of this is randomized. The same training algorithm is used as the last project, but there are just more inputs in this one.</p>
<p>Finally, to classify the input characters, the array of perceptrons is traversed to find the first one that gives an output of 1 when activated with the input. The character corresponding to that perceptron is then rendered in the output box.</p>
<p>Initially, there was a problem where the UI would freeze up during long operations such as generating the training set or training the perceptrons. This was because JavaScript is single threaded and relies on an event loop in the same thread to handle events.</p>
<p>For generating the training set, which requires access to the DOM since it has to render the character into the canvas element, I solved this by changing the loop to use <code>setInterval</code> instead with an interval of 0 so the event loop can run between generating the training samples for each character.</p>
<p>For training the perceptrons and classifying, which don&#39;t require access to the DOM, I solved it by moving them into a web worker. Web workers are a way of achieving parallelism in JavaScript in web browsers. They don&#39;t have access to the DOM and can only communicate with the main thread by posting or receiving messages. So when the train button is pressed, the main thread generates the samples and passes them to the worker in a message. As the worker trains the perceptrons, it periodically sends back the progress of training so it can be displayed on the screen. Then, when the classify button is pressed, the main thread sends the input to the worker, who then sends back which character it was classified as.</p>
<p>Since there is more code than usual in this project, I did not put any code in this post. You can check out the full source code on GitHub.</p>
<h2 id="4-11-2017">4/11/2017</h2>
<p>Today I added the ability to save the trained perceptron data to local storage, so they don&#39;t have to be trained every time the page is refreshed. The weights and threshold of each perceptron are passed to the main thread and saved to local storage.</p>
